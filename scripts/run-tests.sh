#!/bin/bash
# DevGuard Test Runner Script
# Comprehensive test execution with quality gates and reporting

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Configuration
COVERAGE_THRESHOLD=95
MAX_COMPLEXITY=10
TIMEOUT=300

# Function to print colored output
print_header() {
    echo -e "\n${PURPLE}========================================${NC}"
    echo -e "${PURPLE}$1${NC}"
    echo -e "${PURPLE}========================================${NC}\n"
}

print_status() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

print_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# Function to check if command exists
command_exists() {
    command -v "$1" >/dev/null 2>&1
}

# Function to run command with error handling
run_command() {
    local cmd="$1"
    local description="$2"
    
    print_status "Running: $description"
    if eval "$cmd"; then
        print_success "$description completed successfully"
        return 0
    else
        print_error "$description failed"
        return 1
    fi
}

# Function to generate test report
generate_report() {
    local report_file="test-report.html"
    
    print_status "Generating comprehensive test report..."
    
    cat > "$report_file" << EOF
<!DOCTYPE html>
<html>
<head>
    <title>DevGuard Test Report</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .header { background-color: #f0f0f0; padding: 20px; border-radius: 5px; }
        .section { margin: 20px 0; padding: 15px; border: 1px solid #ddd; border-radius: 5px; }
        .success { background-color: #d4edda; border-color: #c3e6cb; }
        .warning { background-color: #fff3cd; border-color: #ffeaa7; }
        .error { background-color: #f8d7da; border-color: #f5c6cb; }
        .metric { display: inline-block; margin: 10px; padding: 10px; background-color: #e9ecef; border-radius: 3px; }
        pre { background-color: #f8f9fa; padding: 10px; border-radius: 3px; overflow-x: auto; }
    </style>
</head>
<body>
    <div class="header">
        <h1>DevGuard Test Report</h1>
        <p>Generated on: $(date)</p>
        <p>Git Branch: $(git branch --show-current 2>/dev/null || echo 'Unknown')</p>
        <p>Git Commit: $(git rev-parse --short HEAD 2>/dev/null || echo 'Unknown')</p>
    </div>
    
    <div class="section">
        <h2>Test Summary</h2>
        <div class="metric">Coverage Threshold: ${COVERAGE_THRESHOLD}%</div>
        <div class="metric">Max Complexity: ${MAX_COMPLEXITY}</div>
        <div class="metric">Timeout: ${TIMEOUT}s</div>
    </div>
EOF

    # Add coverage information if available
    if [ -f "coverage.xml" ]; then
        echo "    <div class=\"section\">" >> "$report_file"
        echo "        <h2>Coverage Report</h2>" >> "$report_file"
        echo "        <p>Detailed coverage report available in <a href=\"htmlcov/index.html\">htmlcov/index.html</a></p>" >> "$report_file"
        echo "    </div>" >> "$report_file"
    fi

    # Add test results if available
    if [ -f "junit-results.xml" ]; then
        echo "    <div class=\"section\">" >> "$report_file"
        echo "        <h2>Unit Test Results</h2>" >> "$report_file"
        echo "        <p>JUnit results available in junit-results.xml</p>" >> "$report_file"
        echo "    </div>" >> "$report_file"
    fi

    cat >> "$report_file" << EOF
    <div class="section">
        <h2>Quality Metrics</h2>
        <p>Quality reports generated by various tools:</p>
        <ul>
            <li>Linting: ruff check results</li>
            <li>Type checking: mypy results</li>
            <li>Security: bandit and safety results</li>
            <li>Formatting: black and isort compliance</li>
        </ul>
    </div>
    
    <div class="section">
        <h2>Files Generated</h2>
        <ul>
            <li>htmlcov/ - HTML coverage report</li>
            <li>coverage.xml - XML coverage report</li>
            <li>junit-results.xml - JUnit test results</li>
            <li>bandit-report.json - Security scan results</li>
            <li>safety-report.json - Dependency security results</li>
        </ul>
    </div>
</body>
</html>
EOF

    print_success "Test report generated: $report_file"
}

# Main execution
main() {
    local test_type="${1:-all}"
    local exit_code=0
    
    print_header "DevGuard Test Runner"
    
    # Check dependencies
    print_status "Checking dependencies..."
    
    if ! command_exists python3; then
        print_error "Python 3 is required but not installed"
        exit 1
    fi
    
    if ! command_exists pytest; then
        print_error "pytest is required but not installed. Run: pip install -e \".[dev]\""
        exit 1
    fi
    
    # Create necessary directories
    mkdir -p logs
    mkdir -p htmlcov
    mkdir -p .coverage_data
    
    # Set environment variables
    export PYTHONPATH="${PYTHONPATH}:$(pwd)/src"
    export TEST_MODE=true
    
    case "$test_type" in
        "all")
            print_header "Running All Tests"
            
            # Code formatting check
            if command_exists black && command_exists isort; then
                run_command "black --check --diff src tests" "Code formatting check" || exit_code=1
                run_command "isort --check-only --diff src tests" "Import sorting check" || exit_code=1
            else
                print_warning "Skipping formatting checks (black/isort not available)"
            fi
            
            # Linting
            if command_exists ruff; then
                run_command "ruff check src tests" "Linting check" || exit_code=1
            else
                print_warning "Skipping linting (ruff not available)"
            fi
            
            # Type checking
            if command_exists mypy; then
                run_command "mypy src tests" "Type checking" || exit_code=1
            else
                print_warning "Skipping type checking (mypy not available)"
            fi
            
            # Security checks
            if command_exists bandit; then
                run_command "bandit -r src -f json -o bandit-report.json" "Security scan" || print_warning "Security scan had issues"
            fi
            
            if command_exists safety; then
                run_command "safety check --json --output safety-report.json" "Dependency security check" || print_warning "Dependency security check had issues"
            fi
            
            # Unit tests
            run_command "pytest tests/unit --cov=src/dev_guard --cov-report=term-missing --cov-report=html:htmlcov --cov-report=xml --cov-fail-under=${COVERAGE_THRESHOLD} --junitxml=junit-results.xml --timeout=${TIMEOUT} -v" "Unit tests" || exit_code=1
            
            # Integration tests (if they exist)
            if [ -d "tests/integration" ] && [ "$(ls -A tests/integration)" ]; then
                run_command "pytest tests/integration --cov=src/dev_guard --cov-append --cov-report=term-missing --cov-report=html:htmlcov --cov-report=xml --junitxml=integration-results.xml --timeout=${TIMEOUT} -v" "Integration tests" || exit_code=1
            else
                print_status "No integration tests found, skipping"
            fi
            ;;
            
        "unit")
            print_header "Running Unit Tests Only"
            run_command "pytest tests/unit --cov=src/dev_guard --cov-report=term-missing --cov-report=html:htmlcov --cov-report=xml --cov-fail-under=${COVERAGE_THRESHOLD} --junitxml=junit-results.xml --timeout=${TIMEOUT} -v" "Unit tests" || exit_code=1
            ;;
            
        "integration")
            print_header "Running Integration Tests Only"
            if [ -d "tests/integration" ] && [ "$(ls -A tests/integration)" ]; then
                run_command "pytest tests/integration --cov=src/dev_guard --cov-report=term-missing --cov-report=html:htmlcov --cov-report=xml --junitxml=integration-results.xml --timeout=${TIMEOUT} -v" "Integration tests" || exit_code=1
            else
                print_error "No integration tests found"
                exit_code=1
            fi
            ;;
            
        "performance")
            print_header "Running Performance Tests Only"
            if [ -d "tests/performance" ] && [ "$(ls -A tests/performance)" ]; then
                run_command "pytest tests/performance --benchmark-only --benchmark-json=benchmark-results.json -v" "Performance tests" || exit_code=1
            else
                print_error "No performance tests found"
                exit_code=1
            fi
            ;;
            
        "security")
            print_header "Running Security Tests Only"
            if [ -d "tests/security" ] && [ "$(ls -A tests/security)" ]; then
                run_command "pytest tests/security --junitxml=security-test-results.xml -v" "Security tests" || exit_code=1
            else
                print_error "No security tests found"
                exit_code=1
            fi
            ;;
            
        "quality")
            print_header "Running Quality Checks Only"
            
            if command_exists black && command_exists isort; then
                run_command "black --check --diff src tests" "Code formatting check" || exit_code=1
                run_command "isort --check-only --diff src tests" "Import sorting check" || exit_code=1
            fi
            
            if command_exists ruff; then
                run_command "ruff check src tests" "Linting check" || exit_code=1
            fi
            
            if command_exists mypy; then
                run_command "mypy src tests" "Type checking" || exit_code=1
            fi
            
            if command_exists bandit; then
                run_command "bandit -r src -f json -o bandit-report.json" "Security scan" || print_warning "Security scan had issues"
            fi
            ;;
            
        "fast")
            print_header "Running Fast Tests Only"
            run_command "pytest tests/unit -m \"not slow\" --cov=src/dev_guard --cov-report=term-missing --maxfail=5 -x --timeout=60 -v" "Fast tests" || exit_code=1
            ;;
            
        *)
            print_error "Unknown test type: $test_type"
            echo "Usage: $0 [all|unit|integration|performance|security|quality|fast]"
            exit 1
            ;;
    esac
    
    # Generate report
    generate_report
    
    # Final status
    if [ $exit_code -eq 0 ]; then
        print_header "All Tests Completed Successfully! ✅"
    else
        print_header "Some Tests Failed! ❌"
    fi
    
    # Display summary
    echo -e "\n${CYAN}Test Summary:${NC}"
    echo "  📊 Coverage report: htmlcov/index.html"
    echo "  📋 Test report: test-report.html"
    echo "  🔍 Detailed logs in: logs/"
    
    if [ -f "junit-results.xml" ]; then
        echo "  📄 JUnit results: junit-results.xml"
    fi
    
    if [ -f "bandit-report.json" ]; then
        echo "  🔒 Security report: bandit-report.json"
    fi
    
    exit $exit_code
}

# Handle script arguments
if [ "$1" = "--help" ] || [ "$1" = "-h" ]; then
    echo "DevGuard Test Runner"
    echo ""
    echo "Usage: $0 [test_type]"
    echo ""
    echo "Test types:"
    echo "  all          - Run all tests and quality checks (default)"
    echo "  unit         - Run unit tests only"
    echo "  integration  - Run integration tests only"
    echo "  performance  - Run performance tests only"
    echo "  security     - Run security tests only"
    echo "  quality      - Run quality checks only"
    echo "  fast         - Run fast tests only (exclude slow tests)"
    echo ""
    echo "Options:"
    echo "  -h, --help   - Show this help message"
    echo ""
    echo "Environment variables:"
    echo "  COVERAGE_THRESHOLD - Coverage threshold (default: 95)"
    echo "  MAX_COMPLEXITY     - Maximum complexity (default: 10)"
    echo "  TIMEOUT           - Test timeout in seconds (default: 300)"
    exit 0
fi

# Run main function
main "$@"